{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magics: ensures that any changes to the modules loaded below will be re-loaded automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "# load general packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# load modules related to this exercise\n",
    "from model_zucher import zurcher\n",
    "from Solve_NFXP import solve_NFXP\n",
    "import estimate_NFXP as estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before solving the exercise, you should download line_profiler. Line_profiler is a tool to check the performance of our code. To install line_profiler, you can open anaconda prompt and write \"pip install line-profiler\" (without the \" \" of course). If you want to know more about line_profiler, check the link below:\n",
    "\n",
    "https://github.com/rkern/line_profiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the engine replacement model given by:\n",
    "\n",
    "$$\n",
    "V(x,\\varepsilon) = \\max_{d\\in \\{0,1\\}} \\big\\{ u(x,d) + \\varepsilon_d + \\beta\n",
    "\\underbrace{\\int_{X} \\int_{\\Omega} V(x',\\varepsilon') \\pi(x'|x,d) q(\\varepsilon'|x') dx' d\\varepsilon' }_{EV(x,d)} \\big\\}\n",
    "$$\n",
    "\n",
    "Where $ \\varepsilon $ is extreme value Type I distribued and utility is given by:\n",
    "\n",
    "$$\n",
    "u(x,d)=\\left \\{\n",
    "\\begin{array}{ll}\n",
    "    -RC-c(0,\\theta_1) & \\text{if }d=\\text{replace}=1 \\\\\n",
    "    -c(x,\\theta_1) & \\text{if }d=\\text{keep}=0\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "Here\n",
    "\n",
    "- $ RC $ = replacement cost  \n",
    "- $ c(x,\\theta_1) $ = cost of maintenance with preference parameters $ \\theta_1 $  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at ReadMe.txt to get an overview of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Invistigate how the code works, that is ensure you understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.init</li>\n",
    "<li> zurcher.setup</li>\n",
    "<li> zurcher.create_grid</li>\n",
    "<li> zucher.state_transition </li>\n",
    "<li> zucher.bellman </li>\n",
    "\n",
    "You can see how they are called below\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run the code below and make sure you understand what we are printing. \n",
    "What does the last transition probability in each row (equal to 0.05) come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_settings = {\n",
    "    'RC': 0.5,\n",
    "    'n': 12,\n",
    "    'p':[0.65,0.2,0.1]   \n",
    "}\n",
    "model = zurcher(**do_settings)\n",
    "\n",
    "print('Model grid:\\n',model.grid)\n",
    "print('Transition probabilities conditional on not replacing:\\n',model.P1)\n",
    "print('Transition probabilities conditional on replacing:\\n',model.P2)\n",
    "ev,pk, dev = model.bellman(np.zeros((model.n)),output=3)\n",
    "print('Bellman one run:\\n',ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method\n",
    "\n",
    "Next, we need to solve the model. Rust 1987 uses Newton–Kantorovich (NK) theorem to solve the Bellman equation in the engine replacement model. To understand the NK algorithm, consider using the Newton's method to solve the single-variable equation, $f(x)=0$. The Newton method uses the iterative procedure stated below to solve the equation:\n",
    "\n",
    "$$x_{n+1} = x_{n} - \\frac{f(x_n)}{f'(x_n)}$$\n",
    "\n",
    "### 4. Use the Newton's Method to solve the equation below. Fill in the Newton step. Try to vary the starting value and see if the solution changes.\n",
    "\n",
    "\n",
    "$$f(x) = 3x^2 - exp(x)=0$$\n",
    "\n",
    "$$f'(x) = g(x) = 6x-exp(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: 3*x**2-np.exp(x)\n",
    "g = lambda x: 6*x-np.exp(x)\n",
    "\n",
    "def newton(f, g, x0, tol=10e-5, max_iter=100):\n",
    "    delta = 2000\n",
    "    it=0\n",
    "    while (max_iter>= it and tol<delta):\n",
    "        # fill in\n",
    "        delta = abs(x1-x0)\n",
    "        it += 1\n",
    "        x0 = x1\n",
    "    return x1, it\n",
    "\n",
    "\n",
    "x0,it = newton(f = f, g = g, x0 = 5)\n",
    "\n",
    "x = np.linspace(-2, 4, num=100)\n",
    "fx = f(x)\n",
    "plt.plot(x, fx)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "\n",
    "print('Root of f(x):', round(x0,2))\n",
    "print('Number of iterations to archieve convergence:', it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton-Kantorovich\n",
    "\n",
    "Now consider solving the engine replacement model. To do so, we need to find the expected value function that solves the Bellman equation.\n",
    "\n",
    "$$\n",
    "EV(x,d) =  \\Gamma(EV)(x,d) \\quad\\Leftrightarrow\\quad (I - \\Gamma)(EV)(x,d)=\\mathbb{0}\n",
    "$$\n",
    "\n",
    "Similar to the Newton iteration, the **NK iteration** uses the following equation\n",
    "\n",
    "$$\n",
    "EV_{k+1} = EV_{k} - (I-\\Gamma')^{-1} (I-\\Gamma)(EV_k)\n",
    "$$\n",
    "\n",
    "- The new operator is the difference between the identity operator \\$I\\$ and Bellman operator $ \\Gamma  $  \n",
    "- $ \\mathbb{0} $ is zero function  \n",
    "- $ I-\\Gamma' $ is a Fréchet derivative of the operator $ I-\\Gamma $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Solve the model. In order to solve the model, you should understand:\n",
    "<li> solve_NFXP.init</li>\n",
    "<li> solve_NFXP.setup</li>\n",
    "<li> solve_NFXP.poly </li>\n",
    "<li> solve_NFXP.sa </li>\n",
    "<li> solve_NFXP.nk </li>\n",
    "</il>\n",
    "You can see how they are called below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'poly'\n",
    "do_settings_solver = {\n",
    "    'sa_min': 10,\n",
    "    'sa_max': 1000000,  \n",
    "    'printfxp': 2\n",
    "}\n",
    "\n",
    "solver = solve_NFXP(**do_settings_solver)\n",
    "model = zurcher()\n",
    "\n",
    "ev0 = np.zeros((model.n)) # Initial guess\n",
    "if algorithm == 'sa':\n",
    "    ev = solver.sa(model.bellman, ev0)\n",
    "elif algorithm == 'poly':\n",
    "    ev = solver.poly(model.bellman, ev0, beta = model.beta)\n",
    "else:\n",
    "    print('Algorithm must be \"sa\" or \"poly\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Now we have to estimate the model. In order to estimate the model, you should understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.read_busdata </li>\n",
    "<li> estimate_NFXP.estimate  </li>\n",
    "<li> estimate_NFXP.ll  </li>\n",
    "</il>\n",
    "\n",
    "You can see how they are called below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "model = zurcher()\n",
    "\n",
    "# Set-up solver\n",
    "solver = solve_NFXP()\n",
    "\n",
    "# Read the data\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "# Estimate the model\n",
    "import time\n",
    "t0 = time.time()\n",
    "theta0 = [0,0]\n",
    "\n",
    "# args for nfxp estimate\n",
    "nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "t1 = time.time()\n",
    "time = t1-t0\n",
    "\n",
    "# Print the result\n",
    "print(f'Structual estimation using busdata from Rust(1987)')\n",
    "print(f'Beta        = {model.beta:.4f}')\n",
    "print(f'n           = {model.n}')\n",
    "print(f'Sample size = {samplesize}\\n \\n')\n",
    "\n",
    "print(f'Parameters     Estimates    s.e. ') \n",
    "print(f'{pnames[0]}             {theta_hat[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "print(f'{pnames[1]}              {theta_hat[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "print(f'{pnames[2]}(1)           {theta_hat[2]:.4f}     {np.sqrt(Avar[2,2]):.4f}  ')\n",
    "print(f'{pnames[2]}(2)           {theta_hat[3]:.4f}     {np.sqrt(Avar[3,3]):.4f}  ')\n",
    "print(f'{pnames[2]}(3)           {theta_hat[4]:.4f}     {np.sqrt(Avar[4,4]):.4f}  ')\n",
    "print(f'{pnames[2]}(4)           {theta_hat[5]:.4f}     {np.sqrt(Avar[5,5]):.4f}  \\n')\n",
    "\n",
    "\n",
    "print(f'Log-likelihood {-optim_res.fun*samplesize:.2f}') \n",
    "print(f'runtime (seconds) {time:.4f}')\n",
    "print(f'The model converged: {converged}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Try using line_profiler in python. This gives you a lot of information about the performance of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f estimate.ll  -f estimate.estimate estimate.estimate(model, solver,data,theta0=theta0, twostep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev0 = np.zeros((model.n)) # Initial guess\n",
    "%lprun -f solve_NFXP.nk -f solve_NFXP.poly solve_NFXP.poly(solver,model.bellman, ev0, beta = model.beta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. In the code, we are using analytical hessian and gradient. Let us now try to use numerical equivalents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Now try changing the optimizer options, and turn the use of the non-numerical Hessian off . What happens?\n",
    "\n",
    "b) Now also try it with the analytical gradient off, what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alternative_specifications_ex7 as a_s_ex7\n",
    "import warnings\n",
    "# Turn off warnings: We turn of warnings as a result of overflow. This occurs as the optimizer will sometimes guess on non-feasible transition probabilities. \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "model = zurcher()\n",
    "solver = solve_NFXP()\n",
    "\n",
    "#Ordinaty\n",
    "print('BHHH:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=0)\n",
    "\n",
    "\n",
    "# Hessian off\n",
    "print('')\n",
    "print('Hessian is off:')\n",
    "%timeit nfxp_result = a_s_ex7.estimate(model, solver,data, twostep=0,est_type=1)\n",
    "\n",
    "\n",
    "# #Hessian and gradient ofF \n",
    "print('')\n",
    "print('Hessian and gradient are off:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Try estimate the model for different values of $\\beta$. \n",
    "\n",
    "(a) Why can we not estimate $\\beta$?\n",
    "\n",
    "(b) When estimating with different $\\beta$, do the changes in the estimates of c and/or RC make intuitively sense?\n",
    "\n",
    "(c) Can you think of some data/variation, which could allow us to identify $\\beta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARY BETA: \n",
    "Nbeta = 4\n",
    "beta = np.linspace(0.5,0.9999,Nbeta)\n",
    "log_lik = np.nan + np.zeros((Nbeta,1))\n",
    "theta_hats =  np.nan + np.zeros((Nbeta,2))\n",
    "\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "print(f'beta     RC     C       log_lik')\n",
    "for i in range(Nbeta):\n",
    "    \n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'beta': beta[i]\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    theta_hats[i,0] = theta_hat[0]\n",
    "    theta_hats[i,1] = theta_hat[1]\n",
    "    log_lik[i]=-optim_res.fun*samplesize\n",
    "    print(f'{beta[i]:.4f} {theta_hats[i,0]:.4f} {theta_hats[i,1]:.4f} {log_lik[i]} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. We use the latest EV guess to start the solve-procedure even though we change $\\theta$ from one likelihood iteration to another. Why do you think we do that? \n",
    "(a) What if we started over with EV=0 each iteration? Try that and see what happens with the parameters and the numerical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alternative_specifications_ex9 as a_s_ex9 \n",
    "\n",
    "# Ordinary\n",
    "print('Same EV')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,0)\n",
    "nfxp_results_ord, theta_hat_ord = a_s_ex9.estimate(model, solver,data,0)\n",
    "\n",
    "\n",
    "# Change EV=0 in each iteration\n",
    "print('EV=0')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,1)\n",
    "nfxp_results_diff, theta_hat_diff = a_s_ex9.estimate(model, solver,data,1)\n",
    "\n",
    "print('')\n",
    "print(f'                 Same EV       EV=0')\n",
    "print(f'{pnames[0]}               {theta_hat_ord[0]:.4f}       {theta_hat_diff[0]:.4f}')\n",
    "print(f'{pnames[1]}                {theta_hat_ord[1]:.4f}       {theta_hat_diff[1]:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Try setting the maximum number of miles (odometer reading) to 720(multiplied previous maximum by 1.6). Now the absorbing state is much higher. \n",
    "\n",
    "(a) If we adjust the number of grid points as well, so that we have a comparable model (multiply the number of grids by 1.6), do we get a better fit? \n",
    "\n",
    "(b) Try to lower the number of grid points to 175 again. How do the parameters change? Are the changes intuitive? \n",
    "\n",
    "(c) Optional: What if you change the max to 225 and half the number of grids (hint: what goes wrong?)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adjusting Grid-points\n",
    "def adjust_grid_point(maks, n):\n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'max': maks,\n",
    "    'n': n\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "        \n",
    "    # Read the data\n",
    "    data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "    samplesize = data.shape[0]\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    \n",
    "    nfxp_model, result, pnames, theta, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    print(f'Parameters     Estimates    s.e. ') \n",
    "    print(f'{pnames[0]}             {theta[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "    print(f'{pnames[1]}              {theta[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "    print(f'Log-likelihood now {-result.fun*samplesize:.4f}\\n \\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline max = 450, n = 175\n",
    "print(f'Baseline')\n",
    "adjust_grid_point(450,175)\n",
    "\n",
    "# a)  max = 720, n = 280\n",
    "print(f'Question (a)')\n",
    "adjust_grid_point(int(450*1.6),int(175*1.6))\n",
    "\n",
    "# b) max = 720., n = 175\n",
    "print(f'Question (b)')\n",
    "adjust_grid_point(int(450*1.6),175)\n",
    "\n",
    "# c) max =225, n = 175/2\n",
    "print(f'Question (c)')\n",
    "adjust_grid_point(int(450/2),int(175/2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d23f3ceec305a45481076084313530cecc6283a24046b34365f00383ab0a81b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
